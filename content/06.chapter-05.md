
## [Chapter 5. System Implementation]{.page_break_before}{.center}
### 5.1	Implementation Overview

In order to create a knowledge graph representing gene-to-gene relationships, we needed to find a source of data, a machine learning model to get relationships from the data, a way to graph these relationships, and enough processing power to handle these tasks. We are able to achieve this by using the College of Engineering's High Performance Computing (HPC).

The methodology framework is based on the design from “Building a pubmed knowledge graph,” [4]. Instead of relating the nodes by Pubmed entries, the nodes will show gene-to-gene relationships through the relation extraction functionality available in BioBERT [1].

Once we have trained our BioBERT model on the Pubmed data, we will use a TigerGraph schema to map relationships and host our graph on TigerCloud.

#### Data Extraction
For data extraction, we used PubMed abstracts as a data source. To implement this, we are using datasets from HuggingFace. HuggingFace datasets are available in the library called Datasets and can be split into the train, validation, and test sets. HuggingFace was selected because its datasets are easy to manipulate for our intended purpose and contain all the abstracts available on PubMed. Pubmed contains about 35 million articles, which are readily available through HuggingFace

#### Relation Extraction and Normalization
For relation extraction, we used BioBERT pre-trained models on the PubMed datasets and GNormPlus along with sieve-based entity linking for Gene name normalization. We used pre-trained models available through BioBERT on HuggingFace and fine-tuned them using datasets available from “Tagging genes and proteins with BioBERT” [2]. For BioBERTs relation extraction, we use a rule-based approach that will look for gene-to-gene interactions along with relationship types such as passive, reactive, and active. For BioBERTs relation extraction, we used the datasets and fine-tunes the model from “Using knowledge base to refine data augmentation for biomedical relation extraction”[?] on our PubMed data.

#### Graph Database
For the graph database, our project uses TigerGraph. For this portion, we will base it on the Drug Repurposing Knowledge Graph [3] and Pubmed Knowledge Graph [1] that we will fine-tune to meet our specifications and schema. 


### 5.2 Implementation of Developed Solutions

We have implemented the data extraction by using the HuggingFace datasets. From these datasets, we have created train, test, and validation sets. Using the pre-trained BioBERT model, we have trained the model using our test sets with a semi-supervised approach to analyze the model. We calculated the F1 score of the model and deemed it appropriate to continue the rest of implementation. After fine-tuning the model, we used it to run relation extraction on the datasets and find the gene-to-gene interactions and relationships. We then created a knowledge graph utilizing TigerGraph to plot the interactions and relationships we found on the genes. 

#### 5.1.1 Methodology
1. We extracted `pubmed` and `pubmed-summarization` from HuggingFace
2. Fine-tuned the biobert-v1.1 model available through HuggingFace on the Named-entity Recognition datasets made available by BioBERT [?].
3. Used the trained model to predict the gene names in the pubmed dataset
4. Pre-processed the data for Relation Extraction by adding tags around gene names we obtained through the named-entity recognition.

> Example of tagging:
>Like other DPP-4 inhibitors, ENToCHEMoMK sitagliptin KMoCHEMoTNE reduces ENToGENEoMK hemoglobin A1c KMoGENEoTNE (HbA1c), fasting and postprandial glucose by glucose-dependent stimulation of insulin secretion and inhibition of glucagon secretion.	INDIRECT-DOWNREGULATOR

5. Fine-tuned the biobert-v1.1 model for Relation Extraction
6. Used the relation extraction model on the pre-processed pubmed dataset
7. The gene names were used to create nodes and the relations were used to create edges in the Tiger Graph schema
8. We plotted the gene-to-gene relationships in TigerGraph and hosted it on TigerCloud.


### 5.3 Implementation Problems, Challenges, and Lessons Learned

#### Implementation Problems and Challenges
The problems and challenges of implementation include having to workaround the potential downtime of the HPC and connecting the output of the name entity recognition with the relation extraction. 

### Lessons Learned
Lessons we learned are that we should have started implementation earlier to have more time to work through the problems. As well as researched more on similar issues that we had before the implementation phase of the project
