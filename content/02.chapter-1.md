# [Chapter 1]{.page_break_before}{.center}


### 1.1  	Project Goals and Objectives
The goal of this project was to create a usable gene-to-gene knowledge graph to aid in research within the biomedical field. The application takes an input, which is a gene name, and outputs a knowledge graph surrounding the connections of diseases and topics related to the inputted gene. Project objectives consisted of ranking the relevance of the outputs, only giving related results, and giving a result in a reasonable amount of time. 		

### 1.2  	Problem and Motivation
Researchers must analyze research papers and draw connections to other papers in the process of conducting research. The finding and analyzing of research papers can be a very time-consuming process. Gene research is also very scattered; there can be multiple diseases related to a single gene and finding all these connections can be very cumbersome. Our project solves both of these problems by decreasing the time for research, as well as creating a visualization to help in understanding gene relationships.

### 1.3  	Project Application and Impact
Genetic research studies how individual genes or groups of genes affect health and disease. By improving research times and offering more relevant research surrounding the topic of genes, our project will act as a tool for the creation of new technologies or discoveries that will benefit the well-being of society and the prevention and treatment of diseases. 

### 1.4  	Project Results and Deliverables
Our project's results are a knowledge graph over genes and their relationships. The output is a knowledge graph with a label of their connections to a specific gene, which is entered as an input for the tool. Project deliverables consist of eight deliverables. 

#### Deliverable 1: Research problem understanding and preliminary research
The research goal is to find the best correlation papers for an input biomedical gene paper for a map of the most correlated papers and their references.
Preliminary research is currently being conducted in machine learning on text mapping and name entity recognition and biomedical research papers to find similar vocabulary for some pre-mapping for training the model later.

#### Deliverable 2: Collecting data
Biomedical research papers on gene and abstract data will be collected through PubMed and Gene. These abstract data will be mass-collected and analyzed using pre-trained / predefined models like GNormPlus for gene name recognition.

#### Deliverable 3: Pre-processing data
The data from Pubmed is formatted in either XML or TXT. This data will be stored in the HPC cluster with additional storage power by AWS. Currently, the project will utilize DynamoDB for noSQL data as the data input could become more diverse ( Redshift for data warehousing )
This data will be stored and automatically processed using python script with some third-party library besides Pandas.  The data then needs to be pre-processed to become unified xml or json data.

#### Deliverable 4: Name entity recognition and relation extraction
After preprocessing data, the data will be processed using BioBERT for text mining training on HPC Cluster to summarize research papers and further create wording correlation mapping on words and weight parameters for graph database construction (maybe the frequency of having similar words between two paper could become the correlation weight scale between two paper). 
Other parameters like a title / abstract / past collaboration or citations of input paper can be utilized.

#### Deliverable 5: Knowledge Representation
Once the weight correlation is determined for the connections between papers, TigerGraph will be used to initiate a graph database. This will be implemented for visualizing recommendation research papers with a weight scale to reduce preliminary research time and increase research productivity.

#### Deliverable 6: Model Evaluation
The model base will be evaluated and compare the model output statistics to some model / service out there in the market on research paper recommendation.

#### Deliverable 7: Model Deployment
After doing quality assurance, the model was deployed on HPC.

#### Deliverable 8: Driving insights and generating Tableau dashboard
Tableau dashboards can be created to compare metrics between the model produced and other models on the market for performance comparison as well as the current model and previous performance to make decisions based on insights to change the machine learning model parameters for improvements.
